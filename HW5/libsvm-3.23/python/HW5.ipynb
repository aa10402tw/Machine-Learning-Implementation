{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from svmutil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = pd.read_csv('X_train.csv', header=None)\n",
    "# df_label = pd.read_csv('T_train.csv', header=None)\n",
    "# labels = df_label.values\n",
    "# df_data['label'] = labels\n",
    "# df_data.to_csv('train.csv', index=False)\n",
    "\n",
    "# # Execute CMD >> python csv2libsvm.py train.csv train.data 784 True\n",
    "\n",
    "# df_data = pd.read_csv('X_test.csv', header=None)\n",
    "# df_label = pd.read_csv('T_test.csv', header=None)\n",
    "# labels = df_label.values\n",
    "# df_data['label'] = labels\n",
    "# df_data.to_csv('test.csv', index=False)\n",
    "\n",
    "# # Execute CMD >> python csv2libsvm.py test.csv test.data 784 True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Desktop\\碩一上\\Machine Learning\\HW\\Machine-Learning-Implementation\\HW5\\libsvm-3.23\\python\\commonutil.py:28: ResourceWarning: unclosed file <_io.TextIOWrapper name='train.data' mode='r' encoding='cp950'>\n",
      "  for i, line in enumerate(open(data_file_name)):\n",
      "C:\\Users\\USER\\Desktop\\碩一上\\Machine Learning\\HW\\Machine-Learning-Implementation\\HW5\\libsvm-3.23\\python\\commonutil.py:28: ResourceWarning: unclosed file <_io.TextIOWrapper name='test.data' mode='r' encoding='cp950'>\n",
      "  for i, line in enumerate(open(data_file_name)):\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = svm_read_problem(r'train.data')\n",
    "y_test, X_test = svm_read_problem(r'test.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM:\n",
      "Accuracy = 95.08% (2377/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "## Use different kernel functions  (linear, polynomial, and RBF kernels) and have comparison between their performance. \n",
    "linear_model =  svm_train(y_train, X_train, '-t 0' )\n",
    "print('Linear SVM:')\n",
    "p_label, p_acc, p_val = svm_predict(y_test,  X_test, linear_model)\n",
    "\n",
    "poly_model =  svm_train(y_train, X_train, '-t 1' )\n",
    "print('Polynoimal SVM:')\n",
    "p_label, p_acc, p_val = svm_predict(y_test,  X_test, poly_model)\n",
    "\n",
    "RBF_model =  svm_train(y_train, X_train, '-t 2' )\n",
    "print('RBF SVM:')\n",
    "p_label, p_acc, p_val = svm_predict(y_test,  X_test, RBF_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy = 95%\n"
     ]
    }
   ],
   "source": [
    "# use C-SVCdo the grid search\n",
    "m = svm_train(y_test,  X_test, '-s 0 -v 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function svm_train in module svmutil:\n",
      "\n",
      "svm_train(arg1, arg2=None, arg3=None)\n",
      "    svm_train(y, x [, options]) -> model | ACC | MSE\n",
      "    \n",
      "    y: a list/tuple/ndarray of l true labels (type must be int/double).\n",
      "    \n",
      "    x: 1. a list/tuple of l training instances. Feature vector of\n",
      "          each training instance is a list/tuple or dictionary.\n",
      "    \n",
      "       2. an l * n numpy ndarray or scipy spmatrix (n: number of features).\n",
      "    \n",
      "    svm_train(prob [, options]) -> model | ACC | MSE\n",
      "    svm_train(prob, param) -> model | ACC| MSE\n",
      "    \n",
      "    Train an SVM model from data (y, x) or an svm_problem prob using\n",
      "    'options' or an svm_parameter param.\n",
      "    If '-v' is specified in 'options' (i.e., cross validation)\n",
      "    either accuracy (ACC) or mean-squared error (MSE) is returned.\n",
      "    options:\n",
      "        -s svm_type : set type of SVM (default 0)\n",
      "            0 -- C-SVC              (multi-class classification)\n",
      "            1 -- nu-SVC             (multi-class classification)\n",
      "            2 -- one-class SVM\n",
      "            3 -- epsilon-SVR        (regression)\n",
      "            4 -- nu-SVR             (regression)\n",
      "        -t kernel_type : set type of kernel function (default 2)\n",
      "            0 -- linear: u'*v\n",
      "            1 -- polynomial: (gamma*u'*v + coef0)^degree\n",
      "            2 -- radial basis function: exp(-gamma*|u-v|^2)\n",
      "            3 -- sigmoid: tanh(gamma*u'*v + coef0)\n",
      "            4 -- precomputed kernel (kernel values in training_set_file)\n",
      "        -d degree : set degree in kernel function (default 3)\n",
      "        -g gamma : set gamma in kernel function (default 1/num_features)\n",
      "        -r coef0 : set coef0 in kernel function (default 0)\n",
      "        -c cost : set the parameter C of C-SVC, epsilon-SVR, and nu-SVR (default 1)\n",
      "        -n nu : set the parameter nu of nu-SVC, one-class SVM, and nu-SVR (default 0.5)\n",
      "        -p epsilon : set the epsilon in loss function of epsilon-SVR (default 0.1)\n",
      "        -m cachesize : set cache memory size in MB (default 100)\n",
      "        -e epsilon : set tolerance of termination criterion (default 0.001)\n",
      "        -h shrinking : whether to use the shrinking heuristics, 0 or 1 (default 1)\n",
      "        -b probability_estimates : whether to train a SVC or SVR model for probability estimates, 0 or 1 (default 0)\n",
      "        -wi weight : set the parameter C of class i to weight*C, for C-SVC (default 1)\n",
      "        -v n: n-fold cross validation mode\n",
      "        -q : quiet mode (no outputs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(svm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "Accuracy = 95.08% (2377/2500) (classification)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#create a linear kernel matrix for the test data\\n\\nK_test[:,1:]=np.dot(x[200:],x[:200].T)\\nK_test[:,:1]=np.arange(len(x)-200)[:,np.newaxis]+1\\n\\np_label, p_acc, p_val = svm_predict(y[200:],[list(row) for row in K_test], m)\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_kernel(x1, x2): # train/train or train/test\n",
    "    # create dense data for x1 (train)\n",
    "    max_key=np.max([np.max(v.keys()) for v in x1])\n",
    "    arr=np.zeros( (len(x1), len(max_key) ))\n",
    "    for row, vec in enumerate(x1):\n",
    "        for k, v in vec.items():\n",
    "            arr[row][k-1]=v\n",
    "    x1 = arr\n",
    "    \n",
    "    #create dense data for x2\n",
    "    max_key=np.max([np.max(v.keys()) for v in x2])\n",
    "    arr=np.zeros( (len(x2), len(max_key) ))\n",
    "    for row, vec in enumerate(x2):\n",
    "        for k, v in vec.items():\n",
    "            arr[row][k-1]=v\n",
    "    x2 = arr\n",
    "    \n",
    "    #create a linear kernel matrix \n",
    "    k = np.zeros( (len(x2), len(x1)+1) )\n",
    "    k[:,1:] = np.dot(x2,x1.T)\n",
    "    k[:,:1] = np.arange(len(x2))[:,np.newaxis]+1\n",
    "    \n",
    "    kernel = [list(row) for row in k]\n",
    "    return kernel\n",
    "\n",
    "\n",
    "x_train = X_train[:]\n",
    "kernel = create_kernel(x_train, x_train)\n",
    "linear_model = svm_train(y_train, kernel, '-t 4')\n",
    "\n",
    "x_test = X_test[:]\n",
    "kernel = create_kernel(x_train, x_test)\n",
    "p_label, p_acc, p_val = svm_predict(y_test, kernel, linear_model)\n",
    "\n",
    "# #create a linear kernel matrix for the test data\n",
    "# x_test = np.zeros( (2500, 5001) )\n",
    "# K_test[:,1:]=np.dot(x[200:],x[:200].T)\n",
    "# K_test[:,:1]=np.arange(len(x)-200)[:,np.newaxis]+1\n",
    "'''\n",
    "#create a linear kernel matrix for the test data\n",
    "\n",
    "K_test[:,1:]=np.dot(x[200:],x[:200].T)\n",
    "K_test[:,:1]=np.arange(len(x)-200)[:,np.newaxis]+1\n",
    "\n",
    "p_label, p_acc, p_val = svm_predict(y[200:],[list(row) for row in K_test], m)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
