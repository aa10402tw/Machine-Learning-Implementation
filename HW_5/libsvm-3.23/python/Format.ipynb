{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from svmutil import *\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Preprocessed data\n",
    "y_train, X_train = svm_read_problem(r'train.data')\n",
    "y_test, X_test = svm_read_problem(r'test.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM:\n",
      "Accuracy = 95.08% (2377/2500) (classification)\n",
      "\n",
      "Polynoimal SVM:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7e7cbee379f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nPolynoimal SVM:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mpoly_model\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0msvm_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-t 1'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mp_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoly_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\KuanWenProject\\ML_implement\\HW5\\libsvm-3.23\\python\\svmutil.py\u001b[0m in \u001b[0;36msvm_train\u001b[1;34m(arg1, arg2, arg3)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0mACC\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                 \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoPyModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train & Test on different kernel\n",
    "print('Linear SVM:')\n",
    "linear_model =  svm_train(y_train, X_train, '-t 0' )\n",
    "p_label, p_acc, p_val = svm_predict(y_test,  X_test, linear_model)\n",
    "\n",
    "print('\\nPolynoimal SVM:')\n",
    "poly_model =  svm_train(y_train, X_train, '-t 1' )\n",
    "p_label, p_acc, p_val = svm_predict(y_test,  X_test, poly_model)\n",
    "\n",
    "print('\\nRBF SVM:')\n",
    "RBF_model =  svm_train(y_train, X_train, '-t 2' )\n",
    "p_label, p_acc, p_val = svm_predict(y_test,  X_test, RBF_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(y_train, X_train, args='-t 2 -v 5 -q', para_range= {'c':[1,2,3], 'g':[None], 'd':[None], 'r':[None]} ):\n",
    "    best_acc = 0.0\n",
    "    best_para = {'c':0, 'g':0, 'd':0, 'r':0}\n",
    "    for c in para_range['c']:\n",
    "        for g in para_range['g']:\n",
    "            for d in para_range['d']:\n",
    "                for r in para_range['r']:\n",
    "                    arg_c = '' if c is None else ' -c %s '%str(c)\n",
    "                    arg_g = '' if g is None else ' -g %s '%str(g)\n",
    "                    arg_d = '' if d is None else ' -d %s '%str(d)\n",
    "                    arg_r = '' if r is None else ' -r %s '%str(r)\n",
    "                    args_ = args + arg_c + arg_g + arg_d + arg_r  \n",
    "                    acc = svm_train(y_train, X_train, args_)\n",
    "                    if acc > best_acc:\n",
    "                        best_acc = acc\n",
    "                        best_para = {'c':c, 'g':g, 'd':d, 'r':r}\n",
    "    print(\"Best Parameters \", best_para , 'Accuracy :', best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters : {'c': 2, 'g': 0, 'd': 0, 'r': 0} Accuracy : 96.64\n",
      "Best Parameters  {'c': 2, 'g': 0.1, 'd': 2, 'r': 0} Accuracy : 98.14\n",
      "Best Parameters  {'c': 3, 'g': 0.01, 'd': 0, 'r': 0} Accuracy : 98.57\n"
     ]
    }
   ],
   "source": [
    "# Linear\n",
    "grid_search(y_train, X_train, args='-t 0 -v 5 ', para_range= {'c':[1,2,3], 'g':[None], 'd':[None], 'r':[None]})\n",
    "# Poly\n",
    "grid_search(y_train, X_train, args='-t 1 -v 5', para_range= {'c':[1,2,3], 'g':[1e-3, 1e-2, 1e-1], 'd':[3,2,1], 'r':[0,1]} )\n",
    "# RBF\n",
    "grid_search(y_train, X_train, args='-t 2 -v 5', para_range= {'c':[1,2,3,4,5], 'g':[1e-1, 1e-2, 1e-3, 1e-4], 'd':[None], 'r':[None]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM:\n",
      "Accuracy = 95% (2375/2500) (classification)\n",
      "\n",
      "Polynoimal SVM:\n",
      "Accuracy = 97.68% (2442/2500) (classification)\n",
      "\n",
      "RBF SVM:\n",
      "Accuracy = 98.08% (2452/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "# use params found in grid search to train & test model\n",
    "print('Linear SVM:')\n",
    "linear_model =  svm_train(y_train, X_train, '-t 0 -c 2.0' )\n",
    "p_label, p_acc, p_val = svm_predict(y_test,  X_test, linear_model)\n",
    "\n",
    "print('\\nPolynoimal SVM:')\n",
    "poly_model =  svm_train(y_train, X_train, '-t 1 -c 2  -g 0.1  -d 2  -r 0' )\n",
    "p_label, p_acc, p_val = svm_predict(y_test,  X_test, poly_model)\n",
    "\n",
    "print('\\nRBF SVM:')\n",
    "RBF_model =  svm_train(y_train, X_train, '-t 2 -c 3.0  -g 0.01' )\n",
    "p_label, p_acc, p_val = svm_predict(y_test,  X_test, RBF_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "def create_kernel(x1, x2, lam_1=1, lam_2=1): # train/train or train/test\n",
    "    # create dense data for x1 (train)\n",
    "    max_key=np.max([np.max(v.keys()) for v in x1])\n",
    "    arr=np.zeros( (len(x1), len(max_key) ))\n",
    "    for row, vec in enumerate(x1):\n",
    "        for k, v in vec.items():\n",
    "            arr[row][k-1]=v\n",
    "    x1 = np.copy(arr)\n",
    "    \n",
    "    #create dense data for x2\n",
    "    max_key=np.max([np.max(v.keys()) for v in x2])\n",
    "    arr=np.zeros( (len(x2), len(max_key) ))\n",
    "    for row, vec in enumerate(x2):\n",
    "        for k, v in vec.items():\n",
    "            arr[row][k-1]=v\n",
    "    x2 = np.copy(arr)\n",
    "    \n",
    "    #create a linear kernel matrix \n",
    "    k_linear = np.zeros( (len(x2), len(x1)) )\n",
    "    k_linear = np.dot(x2, x1.T)\n",
    "    \n",
    "    #create a RBF kernel matrix \n",
    "    k_RBF = np.zeros( (len(x2), len(x1)) )\n",
    "    k_RBF = rbf_kernel(x2, x1, gamma=0.01)\n",
    "    \n",
    "    #create kernel matrix \n",
    "    k = np.zeros( (len(x2), len(x1)+1) )\n",
    "    k[:,1:] = lam_1*k_linear + lam_2*k_RBF\n",
    "    k[:,:1] = np.arange(len(x2))[:,np.newaxis]+1\n",
    "    \n",
    "    kernel = [list(row) for row in k]\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam_1:0.2, lam_2:0.4 | Accuracy = 95.72% (2393/2500) (classification)\n",
      "lam_1:0.2, lam_2:0.6 | Accuracy = 95.76% (2394/2500) (classification)\n",
      "lam_1:0.2, lam_2:0.8 | Accuracy = 95.92% (2398/2500) (classification)\n",
      "lam_1:0.2, lam_2:1.0 | Accuracy = 96% (2400/2500) (classification)\n",
      "lam_1:0.4, lam_2:0.2 | Accuracy = 95.12% (2378/2500) (classification)\n",
      "lam_1:0.4, lam_2:0.6 | Accuracy = 95.44% (2386/2500) (classification)\n",
      "lam_1:0.4, lam_2:0.8 | Accuracy = 95.48% (2387/2500) (classification)\n",
      "lam_1:0.4, lam_2:1.0 | Accuracy = 95.48% (2387/2500) (classification)\n",
      "lam_1:0.6, lam_2:0.2 | Accuracy = 95.04% (2376/2500) (classification)\n",
      "lam_1:0.6, lam_2:0.4 | Accuracy = 95.16% (2379/2500) (classification)\n",
      "lam_1:0.6, lam_2:0.8 | Accuracy = 95.4% (2385/2500) (classification)\n",
      "lam_1:0.6, lam_2:1.0 | Accuracy = 95.44% (2386/2500) (classification)\n",
      "lam_1:0.8, lam_2:0.2 | Accuracy = 95% (2375/2500) (classification)\n",
      "lam_1:0.8, lam_2:0.4 | Accuracy = 95.12% (2378/2500) (classification)\n",
      "lam_1:0.8, lam_2:0.6 | Accuracy = 95.2% (2380/2500) (classification)\n",
      "lam_1:0.8, lam_2:1.0 | Accuracy = 95.36% (2384/2500) (classification)\n",
      "lam_1:1.0, lam_2:0.2 | Accuracy = 95% (2375/2500) (classification)\n",
      "lam_1:1.0, lam_2:0.4 | Accuracy = 95.08% (2377/2500) (classification)\n",
      "lam_1:1.0, lam_2:0.6 | Accuracy = 95.16% (2379/2500) (classification)\n",
      "lam_1:1.0, lam_2:0.8 | Accuracy = 95.2% (2380/2500) (classification)\n",
      "lam_1:1.0, lam_2:1.0 | Accuracy = 95.32% (2383/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "lam_1_range = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "lam_2_range = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "for lam_1 in lam_1_range:\n",
    "    for lam_2 in lam_2_range:\n",
    "        if lam_1 == lam_2 and lam_1!= 1: continue\n",
    "        print(\"lam_1:%.1f, lam_2:%.1f\"%(lam_1, lam_2), end = ' | ')\n",
    "        kernel = create_kernel(X_train, X_train, lam_1, lam_2)\n",
    "        model = svm_train(y_train, kernel, '-t 4 -c 3 -g 0.01')\n",
    "        kernel = create_kernel(X_train, X_test, lam_1, lam_2)\n",
    "        p_label, p_acc, p_val = svm_predict(y_test, kernel, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
