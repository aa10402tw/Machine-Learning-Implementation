{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from svmutil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = pd.read_csv('X_train.csv', header=None)\n",
    "# df_label = pd.read_csv('T_train.csv', header=None)\n",
    "# labels = df_label.values\n",
    "# df_data['label'] = labels\n",
    "# df_data.to_csv('train.csv', index=False)\n",
    "\n",
    "# # Execute CMD >> python csv2libsvm.py train.csv train.data 784 True\n",
    "\n",
    "# df_data = pd.read_csv('X_test.csv', header=None)\n",
    "# df_label = pd.read_csv('T_test.csv', header=None)\n",
    "# labels = df_label.values\n",
    "# df_data['label'] = labels\n",
    "# df_data.to_csv('test.csv', index=False)\n",
    "\n",
    "# # Execute CMD >> python csv2libsvm.py test.csv test.data 784 True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = svm_read_problem(r'train.data')\n",
    "y_test, X_test = svm_read_problem(r'test.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM:\n",
      "Accuracy = 95.08% (2377/2500) (classification)\n",
      "\n",
      "Polynoimal SVM(degree=1):\n",
      "Accuracy = 94.8% (2370/2500) (classification)\n",
      "\n",
      "Polynoimal SVM(degree=2):\n",
      "Accuracy = 88.24% (2206/2500) (classification)\n",
      "\n",
      "Polynoimal SVM(degree=3):\n",
      "Accuracy = 34.68% (867/2500) (classification)\n",
      "\n",
      "RBF SVM:\n",
      "Accuracy = 95.32% (2383/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "# Use different kernel functions  (linear, polynomial, and RBF kernels) and have comparison between their performance. \n",
    "print('Linear SVM:')\n",
    "linear_model =  svm_train(y_train, X_train, '-t 0' )\n",
    "p_label, p_acc, p_val = svm_predict(y_test,  X_test, linear_model)\n",
    "\n",
    "print('\\nPolynoimal SVM:')\n",
    "poly_model =  svm_train(y_train, X_train, '-t 1' )\n",
    "p_label, p_acc, p_val = svm_predict(y_test,  X_test, poly_model)\n",
    "\n",
    "print('\\nRBF SVM:')\n",
    "RBF_model =  svm_train(y_train, X_train, '-t 2' )\n",
    "p_label, p_acc, p_val = svm_predict(y_test,  X_test, RBF_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF SVM:\n",
      "Accuracy = 98.04% (2451/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "# use C-SVCdo the grid search\n",
    "RBF_model =  svm_train(y_train, X_train, '-t 2 -c 32.0  -g 0.0078125' )\n",
    "print('RBF SVM:')\n",
    "p_label, p_acc, p_val = svm_predict(y_test,  X_test, RBF_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function svm_train in module svmutil:\n",
      "\n",
      "svm_train(arg1, arg2=None, arg3=None)\n",
      "    svm_train(y, x [, options]) -> model | ACC | MSE\n",
      "    \n",
      "    y: a list/tuple/ndarray of l true labels (type must be int/double).\n",
      "    \n",
      "    x: 1. a list/tuple of l training instances. Feature vector of\n",
      "          each training instance is a list/tuple or dictionary.\n",
      "    \n",
      "       2. an l * n numpy ndarray or scipy spmatrix (n: number of features).\n",
      "    \n",
      "    svm_train(prob [, options]) -> model | ACC | MSE\n",
      "    svm_train(prob, param) -> model | ACC| MSE\n",
      "    \n",
      "    Train an SVM model from data (y, x) or an svm_problem prob using\n",
      "    'options' or an svm_parameter param.\n",
      "    If '-v' is specified in 'options' (i.e., cross validation)\n",
      "    either accuracy (ACC) or mean-squared error (MSE) is returned.\n",
      "    options:\n",
      "        -s svm_type : set type of SVM (default 0)\n",
      "            0 -- C-SVC              (multi-class classification)\n",
      "            1 -- nu-SVC             (multi-class classification)\n",
      "            2 -- one-class SVM\n",
      "            3 -- epsilon-SVR        (regression)\n",
      "            4 -- nu-SVR             (regression)\n",
      "        -t kernel_type : set type of kernel function (default 2)\n",
      "            0 -- linear: u'*v\n",
      "            1 -- polynomial: (gamma*u'*v + coef0)^degree\n",
      "            2 -- radial basis function: exp(-gamma*|u-v|^2)\n",
      "            3 -- sigmoid: tanh(gamma*u'*v + coef0)\n",
      "            4 -- precomputed kernel (kernel values in training_set_file)\n",
      "        -d degree : set degree in kernel function (default 3)\n",
      "        -g gamma : set gamma in kernel function (default 1/num_features)\n",
      "        -r coef0 : set coef0 in kernel function (default 0)\n",
      "        -c cost : set the parameter C of C-SVC, epsilon-SVR, and nu-SVR (default 1)\n",
      "        -n nu : set the parameter nu of nu-SVC, one-class SVM, and nu-SVR (default 0.5)\n",
      "        -p epsilon : set the epsilon in loss function of epsilon-SVR (default 0.1)\n",
      "        -m cachesize : set cache memory size in MB (default 100)\n",
      "        -e epsilon : set tolerance of termination criterion (default 0.001)\n",
      "        -h shrinking : whether to use the shrinking heuristics, 0 or 1 (default 1)\n",
      "        -b probability_estimates : whether to train a SVC or SVR model for probability estimates, 0 or 1 (default 0)\n",
      "        -wi weight : set the parameter C of class i to weight*C, for C-SVC (default 1)\n",
      "        -v n: n-fold cross validation mode\n",
      "        -q : quiet mode (no outputs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(svm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam_1:0.0, lam_2:1.0 | Accuracy = 96.04% (2401/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "def create_kernel(x1, x2, lam_1=1, lam_2=1): # train/train or train/test\n",
    "    # create dense data for x1 (train)\n",
    "    max_key=np.max([np.max(v.keys()) for v in x1])\n",
    "    arr=np.zeros( (len(x1), len(max_key) ))\n",
    "    for row, vec in enumerate(x1):\n",
    "        for k, v in vec.items():\n",
    "            arr[row][k-1]=v\n",
    "    x1 = arr\n",
    "    \n",
    "    #create dense data for x2\n",
    "    max_key=np.max([np.max(v.keys()) for v in x2])\n",
    "    arr=np.zeros( (len(x2), len(max_key) ))\n",
    "    for row, vec in enumerate(x2):\n",
    "        for k, v in vec.items():\n",
    "            arr[row][k-1]=v\n",
    "    x2 = arr\n",
    "    \n",
    "    #create a linear kernel matrix \n",
    "    k_linear = np.zeros( (len(x2), len(x1)) )\n",
    "    k_linear = np.dot(x2, x1.T)\n",
    "    \n",
    "    #create a RBF kernel matrix \n",
    "    k_RBF = np.zeros( (len(x2), len(x1)) )\n",
    "    k_RBF = rbf_kernel(x2, x1)\n",
    "    \n",
    "    #create kernel matrix \n",
    "    k = np.zeros( (len(x2), len(x1)+1) )\n",
    "    k[:,1:] = 0*k_linear + lam_2*k_RBF\n",
    "    k[:,:1] = np.arange(len(x2))[:,np.newaxis]+1\n",
    "    \n",
    "    kernel = [list(row) for row in k]\n",
    "    return kernel\n",
    "\n",
    "\n",
    "x_train = X_train[:]\n",
    "lam_1_range = [0]\n",
    "lam_2_range = [1.0]\n",
    "for lam_1 in lam_1_range:\n",
    "    for lam_2 in lam_2_range:\n",
    "        if lam_1 == lam_2 and lam_1!= 1: continue\n",
    "        print(\"lam_1:%.1f, lam_2:%.1f\"%(lam_1, lam_2), end = ' | ')\n",
    "        kernel = create_kernel(x_train, x_train, lam_1, lam_2)\n",
    "        model = svm_train(y_train, kernel, '-t 4 -c 3.0  -g 0.01')\n",
    "        x_test = X_test[:]\n",
    "        kernel = create_kernel(x_train, x_test, lam_1, lam_2)\n",
    "        p_label, p_acc, p_val = svm_predict(y_test, kernel, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(y_train, X_train, args='-t 2 -v 5 -q', para_range= {'c':[1,2,3], 'g':[None], 'd':[None], 'r':[None]} ):\n",
    "    best_acc = 0.0\n",
    "    best_para = {'c':0, 'g':0, 'd':0, 'r':0}\n",
    "    \n",
    "    pbar = tqdm(total = len(para_range['c']) * len(para_range['c']) * len(para_range['d']) * len(para_range['r']) )\n",
    "    for c in para_range['c']:\n",
    "        for g in para_range['g']:\n",
    "            for d in para_range['d']:\n",
    "                for r in para_range['r']:\n",
    "                    arg_c = '' if c is None else ' -c %s '%str(c)\n",
    "                    arg_g = '' if g is None else ' -g %s '%str(g)\n",
    "                    arg_d = '' if d is None else ' -d %s '%str(d)\n",
    "                    arg_r = '' if r is None else ' -r %s '%str(r)\n",
    "                    args_ = args + arg_c + arg_g + arg_d + arg_r  \n",
    "                    print(args_, end=' | ')\n",
    "                    acc = svm_train(y_train, X_train, args_)\n",
    "                    if acc > best_acc:\n",
    "                        best_acc = acc\n",
    "                        best_para = {'c':c, 'g':g, 'd':d, 'r':r}\n",
    "                    pbar.update()\n",
    "    pbar.close()\n",
    "    print(\"Best Parameters \", best_para , 'Accuracy :', best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ef40b40e2d4a90af71019daf29da11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-t 2 -v 5 -c 1  -g 0.1  | Cross Validation Accuracy = 91.88%\n",
      "-t 2 -v 5 -c 1  -g 0.01  | Cross Validation Accuracy = 97.86%\n",
      "-t 2 -v 5 -c 1  -g 0.001  | Cross Validation Accuracy = 96.2%\n",
      "-t 2 -v 5 -c 1  -g 0.0001  | Cross Validation Accuracy = 92.66%\n",
      "-t 2 -v 5 -c 2  -g 0.1  | Cross Validation Accuracy = 92.38%\n",
      "-t 2 -v 5 -c 2  -g 0.01  | Cross Validation Accuracy = 98.08%\n",
      "-t 2 -v 5 -c 2  -g 0.001  | Cross Validation Accuracy = 96.54%\n",
      "-t 2 -v 5 -c 2  -g 0.0001  | Cross Validation Accuracy = 94.26%\n",
      "-t 2 -v 5 -c 3  -g 0.1  | Cross Validation Accuracy = 92.34%\n",
      "-t 2 -v 5 -c 3  -g 0.01  | Cross Validation Accuracy = 98.2%\n",
      "-t 2 -v 5 -c 3  -g 0.001  | Cross Validation Accuracy = 96.86%\n",
      "-t 2 -v 5 -c 3  -g 0.0001  | Cross Validation Accuracy = 95.02%\n",
      "-t 2 -v 5 -c 4  -g 0.1  | Cross Validation Accuracy = 92.48%\n",
      "-t 2 -v 5 -c 4  -g 0.01  | Cross Validation Accuracy = 98%\n",
      "-t 2 -v 5 -c 4  -g 0.001  | Cross Validation Accuracy = 97.02%\n",
      "-t 2 -v 5 -c 4  -g 0.0001  | Cross Validation Accuracy = 95.4%\n",
      "-t 2 -v 5 -c 5  -g 0.1  | Cross Validation Accuracy = 92.48%\n",
      "-t 2 -v 5 -c 5  -g 0.01  | Cross Validation Accuracy = 98.08%\n",
      "-t 2 -v 5 -c 5  -g 0.001  | Cross Validation Accuracy = 97.1%\n",
      "-t 2 -v 5 -c 5  -g 0.0001  | Cross Validation Accuracy = 95.52%\n",
      "\n",
      "Best Parameters  {'c': 3, 'g': 0.01, 'd': None, 'r': None} Accuracy : 98.2\n"
     ]
    }
   ],
   "source": [
    "# RBF\n",
    "grid_search(y_train, X_train, args='-t 2 -v 5', para_range= {'c':[1,2,3,4,5], 'g':[1e-1, 1e-2, 1e-3, 1e-4], 'd':[None], 'r':[None]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395b348abe86454bb7d3f92a39faebb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=54), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-t 1 -v 5 -c 1  -g 0.01  -d 3  -r 0  | Cross Validation Accuracy = 96.44%\n",
      "-t 1 -v 5 -c 1  -g 0.01  -d 3  -r 1  | Cross Validation Accuracy = 97.84%\n",
      "-t 1 -v 5 -c 1  -g 0.01  -d 2  -r 0  | Cross Validation Accuracy = 97.56%\n",
      "-t 1 -v 5 -c 1  -g 0.01  -d 2  -r 1  | Cross Validation Accuracy = 97.48%\n",
      "-t 1 -v 5 -c 1  -g 0.01  -d 1  -r 0  | Cross Validation Accuracy = 96.9%\n",
      "-t 1 -v 5 -c 1  -g 0.01  -d 1  -r 1  | Cross Validation Accuracy = 96.88%\n",
      "-t 1 -v 5 -c 1  -g 0.1  -d 3  -r 0  | Cross Validation Accuracy = 97.68%\n",
      "-t 1 -v 5 -c 1  -g 0.1  -d 3  -r 1  | Cross Validation Accuracy = 98%\n",
      "-t 1 -v 5 -c 1  -g 0.1  -d 2  -r 0  | Cross Validation Accuracy = 98.04%\n",
      "-t 1 -v 5 -c 1  -g 0.1  -d 2  -r 1  | Cross Validation Accuracy = 97.84%\n",
      "-t 1 -v 5 -c 1  -g 0.1  -d 1  -r 0  | Cross Validation Accuracy = 96.84%\n",
      "-t 1 -v 5 -c 1  -g 0.1  -d 1  -r 1  | Cross Validation Accuracy = 96.78%\n",
      "-t 1 -v 5 -c 2  -g 0.01  -d 3  -r 0  | Cross Validation Accuracy = 97.22%\n",
      "-t 1 -v 5 -c 2  -g 0.01  -d 3  -r 1  | Cross Validation Accuracy = 97.86%\n",
      "-t 1 -v 5 -c 2  -g 0.01  -d 2  -r 0  | Cross Validation Accuracy = 97.7%\n",
      "-t 1 -v 5 -c 2  -g 0.01  -d 2  -r 1  | Cross Validation Accuracy = 97.58%\n",
      "-t 1 -v 5 -c 2  -g 0.01  -d 1  -r 0  | Cross Validation Accuracy = 97.02%\n",
      "-t 1 -v 5 -c 2  -g 0.01  -d 1  -r 1  | Cross Validation Accuracy = 97%\n",
      "-t 1 -v 5 -c 2  -g 0.1  -d 3  -r 0  | Cross Validation Accuracy = 97.78%\n",
      "-t 1 -v 5 -c 2  -g 0.1  -d 3  -r 1  | Cross Validation Accuracy = 97.96%\n",
      "-t 1 -v 5 -c 2  -g 0.1  -d 2  -r 0  | Cross Validation Accuracy = 98.14%\n",
      "-t 1 -v 5 -c 2  -g 0.1  -d 2  -r 1  | Cross Validation Accuracy = 98.14%\n",
      "-t 1 -v 5 -c 2  -g 0.1  -d 1  -r 0  | Cross Validation Accuracy = 96.74%\n",
      "-t 1 -v 5 -c 2  -g 0.1  -d 1  -r 1  | Cross Validation Accuracy = 96.8%\n",
      "-t 1 -v 5 -c 3  -g 0.01  -d 3  -r 0  | Cross Validation Accuracy = 97.5%\n",
      "-t 1 -v 5 -c 3  -g 0.01  -d 3  -r 1  | Cross Validation Accuracy = 97.86%\n",
      "-t 1 -v 5 -c 3  -g 0.01  -d 2  -r 0  | Cross Validation Accuracy = 97.9%\n",
      "-t 1 -v 5 -c 3  -g 0.01  -d 2  -r 1  | Cross Validation Accuracy = 97.8%\n",
      "-t 1 -v 5 -c 3  -g 0.01  -d 1  -r 0  | Cross Validation Accuracy = 97.06%\n",
      "-t 1 -v 5 -c 3  -g 0.01  -d 1  -r 1  | Cross Validation Accuracy = 96.94%\n",
      "-t 1 -v 5 -c 3  -g 0.1  -d 3  -r 0  | Cross Validation Accuracy = 97.78%\n",
      "-t 1 -v 5 -c 3  -g 0.1  -d 3  -r 1  | Cross Validation Accuracy = 97.88%\n",
      "-t 1 -v 5 -c 3  -g 0.1  -d 2  -r 0  | Cross Validation Accuracy = 98.02%\n",
      "-t 1 -v 5 -c 3  -g 0.1  -d 2  -r 1  | Cross Validation Accuracy = 98.1%\n",
      "-t 1 -v 5 -c 3  -g 0.1  -d 1  -r 0  | Cross Validation Accuracy = 96.44%\n",
      "-t 1 -v 5 -c 3  -g 0.1  -d 1  -r 1  | Cross Validation Accuracy = 96.62%\n",
      "\n",
      "Best Parameters  {'c': 2, 'g': 0.1, 'd': 2, 'r': 0} Accuracy : 98.14\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d26281e972c454a97d47e4595cac251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Params: -t 0 -v 5 -q -c 1\n",
      "Cross Validation Accuracy = 96.16%\n",
      "\n",
      "Params: -t 0 -v 5 -q -c 2\n",
      "Cross Validation Accuracy = 96.64%\n",
      "\n",
      "Params: -t 0 -v 5 -q -c 3\n",
      "Cross Validation Accuracy = 96.24%\n",
      "\n",
      "Params: -t 0 -v 5 -q -c 4\n",
      "Cross Validation Accuracy = 96.54%\n",
      "\n",
      "Params: -t 0 -v 5 -q -c 5\n",
      "Cross Validation Accuracy = 95.96%\n",
      "\n",
      "Best Parameters : [C=2.000000, None=0.000000] Accuracy : 96.64\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RBF SVM:\n",
      "Accuracy = 98.08% (2452/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "# use para found in grid search \n",
    "# print('Linear SVM:')\n",
    "# linear_model =  svm_train(y_train, X_train, '-t 0 -c 2.0' )\n",
    "# p_label, p_acc, p_val = svm_predict(y_test,  X_test, linear_model)\n",
    "\n",
    "# print('\\nPolynoimal SVM:')\n",
    "# poly_model =  svm_train(y_train, X_train, '-t 1 -c 2  -g 0.1  -d 2  -r 0' )\n",
    "# p_label, p_acc, p_val = svm_predict(y_test,  X_test, poly_model)\n",
    "\n",
    "print('\\nRBF SVM:')\n",
    "RBF_model =  svm_train(y_train, X_train, '-t 2 -c 3.0  -g 0.01' )\n",
    "p_label, p_acc, p_val = svm_predict(y_test,  X_test, RBF_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam_1:0.2, lam_2:0.4 | Accuracy = 95.72% (2393/2500) (classification)\n",
      "lam_1:0.2, lam_2:0.6 | Accuracy = 95.76% (2394/2500) (classification)\n",
      "lam_1:0.2, lam_2:0.8 | Accuracy = 95.92% (2398/2500) (classification)\n",
      "lam_1:0.2, lam_2:1.0 | Accuracy = 96% (2400/2500) (classification)\n",
      "lam_1:0.4, lam_2:0.2 | Accuracy = 95.12% (2378/2500) (classification)\n",
      "lam_1:0.4, lam_2:0.6 | Accuracy = 95.44% (2386/2500) (classification)\n",
      "lam_1:0.4, lam_2:0.8 | Accuracy = 95.48% (2387/2500) (classification)\n",
      "lam_1:0.4, lam_2:1.0 | Accuracy = 95.48% (2387/2500) (classification)\n",
      "lam_1:0.6, lam_2:0.2 | Accuracy = 95.04% (2376/2500) (classification)\n",
      "lam_1:0.6, lam_2:0.4 | Accuracy = 95.16% (2379/2500) (classification)\n",
      "lam_1:0.6, lam_2:0.8 | Accuracy = 95.4% (2385/2500) (classification)\n",
      "lam_1:0.6, lam_2:1.0 | Accuracy = 95.44% (2386/2500) (classification)\n",
      "lam_1:0.8, lam_2:0.2 | Accuracy = 95% (2375/2500) (classification)\n",
      "lam_1:0.8, lam_2:0.4 | Accuracy = 95.12% (2378/2500) (classification)\n",
      "lam_1:0.8, lam_2:0.6 | Accuracy = 95.2% (2380/2500) (classification)\n",
      "lam_1:0.8, lam_2:1.0 | Accuracy = 95.36% (2384/2500) (classification)\n",
      "lam_1:1.0, lam_2:0.2 | Accuracy = 95% (2375/2500) (classification)\n",
      "lam_1:1.0, lam_2:0.4 | Accuracy = 95.08% (2377/2500) (classification)\n",
      "lam_1:1.0, lam_2:0.6 | Accuracy = 95.16% (2379/2500) (classification)\n",
      "lam_1:1.0, lam_2:0.8 | Accuracy = 95.2% (2380/2500) (classification)\n",
      "lam_1:1.0, lam_2:1.0 | Accuracy = 95.32% (2383/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "def create_kernel(x1, x2, lam_1=1, lam_2=1): # train/train or train/test\n",
    "    # create dense data for x1 (train)\n",
    "    max_key=np.max([np.max(v.keys()) for v in x1])\n",
    "    arr=np.zeros( (len(x1), len(max_key) ))\n",
    "    for row, vec in enumerate(x1):\n",
    "        for k, v in vec.items():\n",
    "            arr[row][k-1]=v\n",
    "    x1 = np.copy(arr)\n",
    "    \n",
    "    #create dense data for x2\n",
    "    max_key=np.max([np.max(v.keys()) for v in x2])\n",
    "    arr=np.zeros( (len(x2), len(max_key) ))\n",
    "    for row, vec in enumerate(x2):\n",
    "        for k, v in vec.items():\n",
    "            arr[row][k-1]=v\n",
    "    x2 = np.copy(arr)\n",
    "    \n",
    "    #create a linear kernel matrix \n",
    "    k_linear = np.zeros( (len(x2), len(x1)) )\n",
    "    k_linear = np.dot(x2, x1.T)\n",
    "    \n",
    "    #create a RBF kernel matrix \n",
    "    k_RBF = np.zeros( (len(x2), len(x1)) )\n",
    "    k_RBF = rbf_kernel(x2, x1, gamma=0.01)\n",
    "    \n",
    "    #create kernel matrix \n",
    "    k = np.zeros( (len(x2), len(x1)+1) )\n",
    "    k[:,1:] = lam_1*k_linear + lam_2*k_RBF\n",
    "    k[:,:1] = np.arange(len(x2))[:,np.newaxis]+1\n",
    "    \n",
    "    kernel = [list(row) for row in k]\n",
    "    return kernel\n",
    "\n",
    "\n",
    "\n",
    "lam_1_range = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "lam_2_range = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "for lam_1 in lam_1_range:\n",
    "    for lam_2 in lam_2_range:\n",
    "        if lam_1 == lam_2 and lam_1!= 1: continue\n",
    "        print(\"lam_1:%.1f, lam_2:%.1f\"%(lam_1, lam_2), end = ' | ')\n",
    "        kernel = create_kernel(X_train, X_train, lam_1, lam_2)\n",
    "        model = svm_train(y_train, kernel, '-t 4 -c 3 -g 0.01')\n",
    "        kernel = create_kernel(X_train, X_test, lam_1, lam_2)\n",
    "        p_label, p_acc, p_val = svm_predict(y_test, kernel, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RBF SVM:\n",
      "Accuracy = 98.08% (2452/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "print('\\nRBF SVM:')\n",
    "\n",
    "RBF_model =  svm_train(y_train, X_train, '-t 2 -c 3.0  -g 0.01' )\n",
    "p_label, p_acc, p_val = svm_predict(y_test,  X_test, RBF_model)\n",
    "# print(\"Best Parameters : {'c': 2, 'g': 0, 'd': 0, 'r': 0} Accuracy : 96.64\")\n",
    "# print(\"Best Parameters  {'c': 2, 'g': 0.1, 'd': 2, 'r': 0} Accuracy : 98.14\")\n",
    "# print(\"Best Parameters  {'c': 3, 'g': 0.01, 'd': 0, 'r': 0} Accuracy : 98.57\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 96.04% (2401/2500) (classification)\n"
     ]
    }
   ],
   "source": [
    "# kernel_train = create_kernel(X_train, X_train, lam_1, lam_2)\n",
    "\n",
    "# kernel_test = create_kernel(X_train, X_test, lam_1, lam_2)\n",
    "\n",
    "model = svm_train(y_train, kernel_train, '-t 4 -c 3.0 -g 0.02')\n",
    "p_label, p_acc, p_val = svm_predict(y_test, kernel_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
